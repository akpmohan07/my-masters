## TASK 1 — Examiner-Level Pattern Analysis (what keeps coming up)

### What the examiner is *really* testing

Across papers, the questions cluster into two repeatable “exam engines”:

**ETHICS engine**

* Can you **build an argument** (premises → conclusion), spot bad reasoning (fallacies), and *apply* ethical theory to a modern tech case.
* Heavy repeat on **privacy frameworks** and **structured evaluation tools** (Contextual Integrity, ADAPT canvas).

**LAW engine**

* Can you explain **Irish/EU IT-adjacent statutes** with: *purpose → key provisions → obligations → critique → application to scenario*.
* Heavy repeat on **Data Protection (GDPR/DPA 2018 + DPIA)** and **IP/cybercrime statutes**.

---

## Recurring Ethics questions/themes (high frequency)

### “The Big Four” ethics package (appears repeatedly, often as Q1)

1. **Tech ethics issues + premise/conclusion structure**

   * Automated face recognition appears repeatedly (2019, 2021 resit, 2022, 2024 resit).    
   * Machine learning ethics issues appears (2023, 2024 sem1).  

2. **Natural vs normative privacy + Nissenbaum’s Contextual Integrity**

   * Extremely repeatable; appears across years and resits.     

3. **Ethical theory choice/application (utilitarian/deontological/virtue/contract, etc.)**

   * “Favoured theory and why” / “compare theories on a case” appears often.  

4. **ADAPT ethical canvas**

   * Recurs as a short-mark “describe + use” component.   

### “The Reasoning & Debate” ethics package (also recurring)

* **Discussion stoppers / refusal to engage in ethical debate** repeats.   
* **Moral vs cultural relativism** repeats.   
* **Logical fallacies (+ “when is a fallacy not a fallacy?”)** repeats.   

### Secondary recurring ethics topics (good ROI)

* **ACM code: benefits/drawbacks + applying to conflict of interest** repeats strongly.  
* **Property justification → ethics of software IP** repeats strongly.  
* **Whistleblowing comparisons** recur (WikiLeaks/Snowden etc.).  

---

## Recurring Law questions/themes (high frequency)

### Tier-1 repeat cluster A: Data Protection (the “banker”)

* **GDPR/DPA 2018 principles + organisational obligations** (2024 sem1 explicitly). 
* **DPIA: what/when/how** repeats heavily (2020, 2021 resit, 2023, 2024 sem1).    
* **Sports club + under-age GDPR compliance** repeats across years.   
* **Schrems / international transfers** appears multiple times (esp. resits).  

### Tier-1 repeat cluster B: IP / Software protection

* **Copyright and Other IP Law Provisions Act 2019** repeats across many papers.   
* Often paired with **“advise a start-up: copyright vs patents vs trademarks vs trade secrets”**.  

### Tier-1 repeat cluster C: cybercrime + evidence handling

* **Criminal Justice (Offences relating to Information Systems) Act 2017 / CJ Act 2017** repeats.  
* **Digital evidence collection / first responder best practice** repeats.  

### Strong-but-more-recent cluster: Online Safety

* **Online Safety and Media Regulation Act 2022 / Coimisiún na Meán** appears in newer papers.  

---

# Tier classification (what to study first)

## Tier 1 — MUST STUDY (highest probability)

### Ethics (pick one question, but prep flexible blocks)

1. **Natural vs Normative privacy + Contextual Integrity (Nissenbaum)** 
2. **Ethical theories (utilitarian vs deontological vs virtue vs contract) + applying to a case** 
3. **Tech ethics issues written as arguments (premises→conclusion)** (face recognition or ML)  
4. **Logical fallacies (+ when a fallacy is not a fallacy)** 
5. **Moral vs Cultural relativism** 

### Law

1. **GDPR/DPA 2018 principles + obligations + DPIA** 
2. **Copyright & Other IP Law Provisions Act 2019 + software protection + criticisms** 
3. **Digital evidence handling + first responder best practice + CJ (Information Systems) 2017 offences**  
4. **Online Safety and Media Regulation Act 2022 + Coimisiún na Meán (functions/effects)** 

## Tier 2 — Good to study (high ROI if time)

### Ethics

* **ADAPT ethical canvas** 
* **ACM Code: benefits/drawbacks + conflict of interest** 
* **Whistleblowing comparisons / guidelines** 

### Law

* **Defamation Act 2009 defences + online cases** 
* **Schrems / transfers (as an add-on to GDPR answers)** 
* **FOI Act 2014** 
* **US Cloud Act (as add-on to cloud + data transfers)** 

## Tier 3 — Low ROI / optional (only if comfortable)

* Narrow one-offs (e.g., specific niche case prompts like CRH/CCPC warrant scope; EU AI Act detail questions) unless you’ve seen them in your own 2025 paper set and they’re clearly dominant.

---

## The single best “highest probability” picks

### ONE Ethics topic to bet on

**Natural vs Normative privacy + Contextual Integrity (Nissenbaum), combined with applying an ethical theory to a privacy/security case.**
Why: it’s *repeat-heavy* and it also lets you flex writing/analysis rather than memorising lists.  

### ONE Law topic to bet on

**GDPR/DPA 2018 + DPIA (what/when/how) + organisational obligations.**
Why: the papers keep returning to it in multiple formats (principles, DPIA, children/club scenario).  

### “Safe to ignore if time runs short”

* Ethics: deep-diving niche cases (Pandora/Wikileaks specifics, “Facebook files” detail) — you can still reference them lightly as examples without mastering facts. 
* Law: very case-specific “one-off” prompts (unless your 2025 paper has them again). Keep a *one-paragraph* awareness only.

---

# TASK 2 — Zero-Knowledge Teaching for Tier 1 (exam-optimised)

Below is exactly what earns marks: **definition → structured points → apply to scenario → mini-critique → conclusion**.

---

## ETHICS TIER 1.1 — Natural vs Normative privacy + Contextual Integrity

### Why it’s named that

* **Natural** = “privacy as it exists/describes reality” (what people actually do/expect).
* **Normative** = “privacy as it ought to be” (what is justified, right, protected).

### Examiner-expected definitions

* **Natural privacy:** descriptive account of privacy practices/expectations in society.
* **Normative privacy:** prescriptive account: what privacy protections people *should* have.
* **Contextual Integrity (Nissenbaum):** privacy is preserved when **information flows** match the **norms of a context** (who, what, why, how). Breach occurs when flow violates contextual norms. 

### Core points that score

* **Don’t treat privacy as “secrecy only”**: it’s about *appropriate flow*.
* CI analysis (easy marks): identify:

  * **Context** (healthcare, education, banking, workplace)
  * **Actors** (sender, subject, recipient)
  * **Attributes** (type of data)
  * **Transmission principle** (consent? necessity? legal duty? confidentiality?)
* **Natural vs normative**: show you can say:

  * “Even if people *are used to* surveillance (natural), it may still be wrong (normative).”

### 2–3 reusable examples

* **Phone data breach / state access** (recurs). 
* **Professor sharing alumni emails** (education context). 
* **App/Instagram data flows** (commercial + minors). 

### Typical marks (how they allocate)

* ~30–40%: correct definitions + CI components
* ~40–50%: applying CI step-by-step to the scenario
* ~10–20%: critique/limits (e.g., contexts evolve; power imbalance; unclear norms)

### How examiners award marks

* They tick off **named elements** (actors/attributes/transmission principle).
* They reward **clear “therefore” reasoning**: “Because the transmission principle was X, the flow violates context Y.”

---

## ETHICS TIER 1.2 — Ethical theories (and applying them)

### Why it’s named that

* Each theory is a *lens*: it tells you what counts as a “good reason” in ethics.

### Examiner-expected definitions (tight)

* **Utilitarianism (consequentialism):** right act maximises overall welfare/utility.
* **Deontology:** right act follows duties/rights/rules regardless of outcome.
* **Virtue ethics:** right act expresses good character (virtues) in context.
* **Social contract:** right rules are those rational people would accept for mutual benefit.

### Core arguments/points

* For each theory, you need:

  * **Decision rule** (how it decides)
  * **Strength** (why it’s appealing)
  * **Weakness** (what it can miss)
* Then **apply to a case** (FBI v Apple, spyware, security vs privacy).  

### 2–3 reusable examples

* **Encryption backdoor debate (FBI v Apple)** (utility vs rights). 
* **Spyware** (deontology: consent/rights; virtue: integrity/temperance). 
* **Security vs privacy** (balancing + rights framing). 

### Typical marks

* Definitions (~20%)
* Comparison/contrast (~30%)
* Application to facts (~40%)
* Critical reflection (~10%)

### Examiner marking behaviour

* Big reward for **explicitly separating**: “Utilitarian answer would be…, Deontological answer would be…”
* Extra credit for acknowledging **uncertainty and trade-offs** without going vague.

---

## ETHICS TIER 1.3 — Writing “ethical issues” as arguments (premises → conclusion)

### Examiner-expected definition

* An **argument**: premises offered as reasons supporting a conclusion.
* A good “ethical issue” answer: *ethical claim* supported by *reasons*, then linked to *harms/rights/virtues/context*.

### How to generate 3 issues fast (template)

For each issue:

1. **Name the issue** (e.g., bias/discrimination)
2. Give **3 premises** (facts + ethical principles)
3. **Conclusion** (therefore, X is unethical/needs restriction)

### Reusable issue-buckets (face recognition OR ML)

* **Bias/disparate impact**
* **Consent + surveillance creep**
* **Chilling effects + autonomy**
* **Error rates + due process**
* **Power imbalance (state/corporate vs individual)**

(Use whichever tech the paper asks: face recognition  or ML .)

### Typical marks

* 3 issues × (premises + conclusion) = most marks
* A short “mitigation” line after each issue often pushes you into higher bands.

### What wins marks

* Premises that mix:

  * **empirical** (“system has error rates / is deployed widely”)
  * **normative** (“people have a right not to be tracked without justification”)
* Clear “therefore” conclusion.

---

## ETHICS TIER 1.4 — Logical fallacies (+ when is a fallacy not a fallacy)

### Why it’s named that

* A “fallacy” is a **pattern of reasoning** that *seems* persuasive but is unreliable.

### Examiner-expected definition

* **Logical fallacy:** an error in reasoning that undermines the argument’s validity/strength. 

### Core fallacies (pick 4 and master)

Use this 4-pack because it matches recurring lists:

* **Appeal to authority** (authority isn’t relevant/expert OR topic is disputed) 
* **Ad hominem** (attack person, not argument) 
* **Anecdotal fallacy** (story ≠ evidence) 
* **Texas sharpshooter** (cherry-picking patterns) 

### “When is a fallacy not a fallacy?”

This is a common twist. Your scoring answer:

* A *named pattern* isn’t automatically wrong if the **missing conditions are satisfied**.

  * Example: appeal to authority is *not* fallacious when the authority is **relevant, qualified, and there is consensus**.

### Typical marks

* Definition (~20%)
* Each fallacy: explain + why it fails + example (~70%)
* “Not a fallacy when…” (~10%)

### How examiners tick-box

* They look for **(i)** name, **(ii)** structure of the wrong inference, **(iii)** example, **(iv)** boundary condition.

---

## ETHICS TIER 1.5 — Moral vs Cultural relativism

### Why it’s named that

* **Moral** relativism: right/wrong depends on individual belief.
* **Cultural** relativism: right/wrong depends on cultural norms.

### Examiner-expected definitions

* **Moral relativism:** moral truth varies by person; no objective standard.
* **Cultural relativism:** moral norms are culture-bound; judging across cultures is problematic.

### Core exam points

* Strength: promotes tolerance / reduces ethnocentrism.
* Weakness: can excuse oppression; makes moral criticism difficult.
* Apply to a state privacy case: “a government does X; is it ‘acceptable’ there?” (then critique using rights/harms/CI). 

### Reusable examples

* Website blocking / censorship (state context). 
* Government phone data access. 

### Marking

* Definitions + difference = easy marks
* Best answers add: **a middle position** (respect culture but still allow human-rights critique).

---

# LAW TIER 1.1 — GDPR / Data Protection Act 2018 + DPIA

### Examiner-expected definitions

* **GDPR principles** (as implemented via DPA 2018): core rules for lawful processing + accountability obligations. 
* **DPIA:** a documented risk assessment required for **high-risk processing**, identifying risks to rights/freedoms and mitigations. 

### What to write (structure that scores)

1. **Purpose**: protect individuals; regulate processing; enforce accountability.
2. **Principles** (name + 1 line each):

   * lawfulness/fairness/transparency
   * purpose limitation
   * data minimisation
   * accuracy
   * storage limitation
   * integrity/confidentiality
   * accountability
3. **Organisational obligations**:

   * lawful basis, notices, data subject rights handling, security measures, breach response, processor contracts, records.
4. **DPIA**:

   * When required (high risk/new tech/large-scale sensitive data/systematic monitoring etc.)
   * Steps: describe processing → assess necessity/proportionality → identify risks → mitigations → consult DPO; consult DPC if residual high risk.
5. **Apply to scenario** (sports club under-age is a repeat-friendly scenario). 

### Reusable examples

* Under-age membership club: consent/guardians, safeguarding, minimisation. 
* New product with monitoring → DPIA. 

### Typical marks

* Principles named correctly (big chunk)
* DPIA definition + trigger + step-by-step method
* Application (scenario-specific controls)

### Examiner behaviour

* They award heavily for **complete lists of principles** and a **procedural DPIA workflow**.

---

## LAW TIER 1.2 — Copyright & Other IP Law Provisions Act 2019 (software angle)

### Examiner-expected definition

* A modernising Irish IP statute; you must describe **main features** and then **criticise from software protection viewpoint**. 

### How to answer without memorising sections

Use an “IP-protection” frame:

1. **What copyright protects in software** (expression/code, not ideas/functionality).
2. **Why that’s a problem** (software value often lies in function/UX/algorithms).
3. **How the Act tries to modernise** (digital environment, enforcement, etc.)
4. **Criticisms** (exam loves this):

   * still weak on functional imitation
   * enforcement difficulties online
   * imbalance between innovation and access
5. **Practical advice to a start-up** (tie to the recurring “choose protections” prompt):

   * copyright (code), trademarks (brand), trade secrets (models/weights), patents (if available/strategic)

### Reusable examples

* Start-up SaaS: trademark name + copyright code + trade secrets for model pipeline
* Open-source use: compliance + licensing risks
* Copycat app: UI/function copied but not code → gap between “idea vs expression”

### Marking

* Features (knowledge)
* Software-specific critique (analysis)
* Applied advice (professional practice)

---

## LAW TIER 1.3 — Digital evidence + first responder best practice + CJ 2017 offences

### Examiner-expected items

* **First responder guidelines**: preserve integrity, document chain of custody, avoid altering data, isolate devices correctly, secure logs. 
* **CJ (Information Systems) 2017**: describe cybercrime offences + how act could be improved. 

### How to write it (scoring layout)

1. Define: **digital evidence** + why fragile.
2. **Golden rules**

   * minimal handling
   * contemporaneous notes
   * hash/verification
   * secure storage
   * continuity/chain of custody
3. Search & seizure: legal authority + proportionality + scope control.
4. Mention special category: abusive images → strict access controls, specialist procedures (only as a high-level line; don’t over-detail).
5. CJ 2017 offences (write as a list + 1 line each), then improvements (clarity, resourcing, cross-border cooperation).

---

## LAW TIER 1.4 — Online Safety & Media Regulation Act 2022 + Coimisiún na Meán

### What it’s “for” (naming logic)

* “Online Safety” = regulation of harmful content/systems; “Media Regulation” = modern regulator mandate; the Commission is the enforcement body. 

### Examiner-expected points

* Role of the authority (functions/responsibilities) 
* Predicted **effects**: governance, compliance duties, content oversight mechanisms, accountability.

### Marking

* They reward: “purpose → mechanisms → impact → critique (what remains to be addressed)”.

---

# TASK 4 — Answer-Writing Blueprint (what examiners love)

## Ethics essay structure (high scoring)

1. **Define** the key concepts in the question (2–4 lines each)
2. **Framework**: state the tool you’ll use (CI / theory comparison / argument structure)
3. **Apply** step-by-step to the scenario (this is the bulk)
4. **Counter-argument** (1 paragraph) + response
5. **Conclusion**: balanced judgement + conditions/mitigations

## Law essay structure (high scoring)

1. **Purpose** of the statute/regime
2. **Key provisions/principles** (named, explained)
3. **Obligations/procedures** for organisations
4. **Apply to scenario** (controls, compliance steps)
5. **Critique/improvements** (short but specific)
6. **Conclusion**

---

## Full exam-perfect outlines (NOT full essays)

### Ethics outline (most reusable): Natural vs Normative privacy + Contextual Integrity

**Intro**

* Define natural vs normative privacy.
* Define Contextual Integrity as “appropriate information flow by contextual norms.”

**Body 1 — Set up CI method**

* Identify context
* Actors (sender/subject/recipient)
* Attribute type
* Transmission principle

**Body 2 — Apply to scenario (e.g., phone data access / professor email sharing)**

* Walk through each CI element and show mismatch
* Explain harms: autonomy, chilling effect, power imbalance
* Distinguish: “natural acceptance” vs “normative justification”

**Body 3 — Ethical theory overlay (short)**

* Utilitarian: welfare/security gains vs societal cost
* Deontology: rights/consent/due process
* Virtue/contract: trust, integrity, legitimacy

**Counter-argument**

* “Security necessity / implied consent / public interest”
* Respond with proportionality, minimisation, safeguards, oversight

**Conclusion**

* Clear judgement + conditions for ethical acceptability (narrow scope, transparency, independent oversight, minimisation)

---

### Law outline (banker): GDPR/DPA 2018 principles + DPIA

**Intro**

* Purpose of GDPR/DPA 2018
* Define DPIA and why it exists (risk to rights/freedoms)

**Body 1 — Principles**

* List principles, each with a 1–2 line explanation

**Body 2 — Organisational obligations**

* Lawful basis, transparency notices, rights handling, security, breach response, processor management, records/accountability

**Body 3 — DPIA**

* When required (high risk processing)
* DPIA steps in order
* Outcome: mitigations; consult regulator if residual high risk

**Apply to scenario**

* Example: under-age sports club / new product monitoring
* Controls: minimisation, access control, retention limits, consent/guardian management (if relevant), staff training, incident handling

**Critique**

* Compliance burden; ambiguity of “high risk”; cross-border issues

**Conclusion**

* Summarise compliance pathway + risk reduction

---

# TASK 5 — Survival & Choice Strategy (only 60–70% coverage)

## Which question to choose (rule)

Pick the question where you can do **all three**:

* define terms confidently
* apply a framework step-by-step
* produce at least one criticism/counterargument

### If Ethics choice is unclear in the exam

* If you see **privacy / data breach / surveillance / security vs privacy** → choose it (you can deploy CI + theory).
* If you see **fallacies/relativism/discussion-stoppers** → choose it if you’re strong at structured explanation + examples.

### If Law choice is unclear

* If you see **GDPR / DPA 2018 / DPIA / obligations** → choose it every time. 

## How to adapt to unfamiliar wording (the examiner trick)

* Translate the question into one of your prepared “engines”:

  * Ethics unknown tech (drones/ML/face recognition) → run: **3 issues as arguments + 1 theory + 1 mitigation**
  * Law unknown statute → run: **purpose → key provisions → obligations → apply → critique**

## “Bluff” without losing marks (safe version)

You don’t invent facts. You **generalise correctly**:

* Use conditional language: “Typically, such regimes require…” then tie back to principles (transparency, necessity, proportionality, accountability).
* Keep examples generic but plausible (workplace, education, healthcare) and focus on *reasoning*.

## High-stakes time management inside the 2 hours

* 5 min: choose questions + jot skeleton
* 50 min: write Ethics
* 50 min: write Law
* 10 min: add missing definitions + conclusion + one critique line in each

---

If you want, paste *one* ethics question and *one* law question from your **most recent** paper set (the one closest to your sitting), and I’ll map your “banker outlines” onto them line-by-line (still outlines only).
